Papers: 

* [TRANSFORMING PHOTOS TO COMICS USING CONVOLUTIONAL NEURAL NETWORKS
](https://orca.cf.ac.uk/100937/1/transforming-photos-comics-ICIP2017.pdf)

* [Neural Photo Editing with Introspective Adversarial Networks
](https://arxiv.org/abs/1609.07093)

* [CHEST RADIOGRAPH CLASSIFICATION
](https://arxiv.org/abs/1909.01940)

* [Deep Learning Face Attributes in the Wild
](https://arxiv.org/abs/1411.7766)

* [Alpha Zero](https://kstatic.googleusercontent.com/files/2f51b2a749a284c2e2dfa13911da965f4855092a179469aedd15fbe4efe8f8cbf9c515ef83ac03a6515fa990e6f85fd827dcd477845e806f23a17845072dc7bd)

* [A Neural Algorithm of Artistic Style](https://arxiv.org/abs/1508.06576)
* [A Neural Algorithm of Artistic Style2](http://openaccess.thecvf.com/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf)
* [A Neural Algorithm of Artistic Style pytorch implementation](https://github.com/jcjohnson/neural-style)

* [Very Deep Convolutional Networks for Large-Scale Image Recognition
](https://arxiv.org/abs/1409.1556)

* [Instance Normalization: The Missing Ingredient for Fast Stylization
](https://arxiv.org/abs/1607.08022)

Paper about image colorization:

* [Colorful Image Colorization
](http://richzhang.github.io/colorization/)
Ten jest najlepszy. Opiera się na wielu sieciach konwolucyjnych, co prawda cały model
jest dosyć duży, ale chyba będziemy w stanie jakoś go użyć.

* [Exploring Convolutional Neural Networks for Automatic Image Colorization
](http://cs231n.stanford.edu/reports/2017/pdfs/409.pdf)
Ten paper w zasadzie wzoruje się na tym powyższym, ale go upraszcza, to w skrócie 
taka trochę prostsza, napisana łatwiejszym językiem wersja tego powyższego, więc moim zdaniem tym paperem
możemy się inspirować do naszej sieci, a tego powyższego użyć jako źródło do cytatów. I w tym i tym powyższym jest 
dokładny opis struktur sieci.

* [Coloring black and white world using Deep Neural Nets
](http://cs231n.stanford.edu/reports/2016/pdfs/205_Report.pdf)
Ten paper jest taki trochę w kit, bo oni tutaj najpierw używają już gotowej sieci
do feature extraction i dopiero potem dodają coś swojego, wiec moim zdaniem nie wiele 
możemy z tego papera wyciągnąc dla nas, no ale się zobaczy.

